{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "united-composite",
   "metadata": {},
   "source": [
    "# Apprentice Chef\n",
    "\n",
    "### A1: Regression Model Development\n",
    "Estrella Spaans | Machine Learning\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "After three years serving customers across the San Francisco Bay Area, the executives at Apprentice Chef have decided to take on an analytics project to better understand how much revenue to expect from each customer within their first year of using their services.Thus, they have hired you on a full-time contract to analyze their data, develop your top insights, and build a machine learning model to predict revenue over the first year of each customer’s life cycle.They have explained to you that for this project, they are not interested in a time series analysis and instead would like to “keep things simple” by providing you with a data set of aggregated customer information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-experience",
   "metadata": {},
   "source": [
    "## 1. Data Preperation\n",
    "\n",
    "In here, I imported the essential packages and uploaded the file as a dataframe. In the description, it was mentioned that one of th columns was mislabeled, so I changed 'LARGEST_ORDER_SIZE' to 'AVERAGE_MEALS_ORDERED'. I also changed the columns names to lowercase as this is easier for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ethical-westminster",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>cross_sell_success</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>first_name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>total_meals_ordered</th>\n",
       "      <th>unique_meals_purch</th>\n",
       "      <th>contacts_w_customer_service</th>\n",
       "      <th>product_categories_viewed</th>\n",
       "      <th>avg_time_per_site_visit</th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>cancellations_before_noon</th>\n",
       "      <th>cancellations_after_noon</th>\n",
       "      <th>tastes_and_preferences</th>\n",
       "      <th>pc_logins</th>\n",
       "      <th>mobile_logins</th>\n",
       "      <th>weekly_plan</th>\n",
       "      <th>early_deliveries</th>\n",
       "      <th>late_deliveries</th>\n",
       "      <th>package_locker</th>\n",
       "      <th>refrigerated_locker</th>\n",
       "      <th>avg_prep_vid_time</th>\n",
       "      <th>average_meals_ordered</th>\n",
       "      <th>master_classes_attended</th>\n",
       "      <th>median_meal_rating</th>\n",
       "      <th>avg_clicks_per_visit</th>\n",
       "      <th>total_photos_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Saathos</td>\n",
       "      <td>saathos@unitedhealth.com</td>\n",
       "      <td>Saathos</td>\n",
       "      <td>Saathos</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1365.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alysanne Osgrey</td>\n",
       "      <td>alysanne.osgrey@ge.org</td>\n",
       "      <td>Alysanne</td>\n",
       "      <td>Osgrey</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>40.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Edwyd Fossoway</td>\n",
       "      <td>edwyd.fossoway@jnj.com</td>\n",
       "      <td>Edwyd</td>\n",
       "      <td>Fossoway</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>19.77</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Eleyna Westerling</td>\n",
       "      <td>eleyna.westerling@ge.org</td>\n",
       "      <td>Eleyna</td>\n",
       "      <td>Westerling</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Elyn Norridge</td>\n",
       "      <td>elyn.norridge@jnj.com</td>\n",
       "      <td>Elyn</td>\n",
       "      <td>Norridge</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>40.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   revenue  cross_sell_success               name                     email first_name family_name  total_meals_ordered  unique_meals_purch  contacts_w_customer_service  product_categories_viewed  avg_time_per_site_visit  mobile_number  cancellations_before_noon  cancellations_after_noon  tastes_and_preferences  pc_logins  mobile_logins  weekly_plan  early_deliveries  late_deliveries  package_locker  refrigerated_locker  avg_prep_vid_time  average_meals_ordered  master_classes_attended  median_meal_rating  avg_clicks_per_visit  total_photos_viewed\n",
       "0    393.0                   1            Saathos  saathos@unitedhealth.com    Saathos     Saathos                   14                   6                           12                         10                    48.00              1                          3                         1                       1          5              2            0                 0                2               0                    0               33.4                      1                        0                   1                    17                    0\n",
       "1   1365.0                   1    Alysanne Osgrey    alysanne.osgrey@ge.org   Alysanne      Osgrey                   87                   3                            8                          8                    40.35              1                          0                         0                       1          5              1           12                 0                2               0                    0               84.8                      1                        0                   3                    13                  170\n",
       "2    800.0                   1     Edwyd Fossoway    edwyd.fossoway@jnj.com      Edwyd    Fossoway                   15                   7                           11                          5                    19.77              1                          3                         0                       1          6              1            1                 0                1               0                    0               63.0                      1                        0                   2                    16                    0\n",
       "3    600.0                   1  Eleyna Westerling  eleyna.westerling@ge.org     Eleyna  Westerling                   13                   6                           11                          5                    90.00              1                          2                         0                       1          6              1           14                 0                3               0                    0               43.8                      1                        0                   2                    14                    0\n",
       "4   1490.0                   1      Elyn Norridge     elyn.norridge@jnj.com       Elyn    Norridge                   47                   8                            6                         10                    40.38              1                          0                         0                       0          5              1            5                 0                8               0                    0               84.8                      1                        1                   3                    12                  205"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PACKAGES, FILE, CHANGES AND SHOWING DATA \n",
    "## 1. IMPORTANT PACKAGES\n",
    "import pandas as pd # essential datascience package\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import numpy as np # mathimatical functions \n",
    "import seaborn as sns  # enhanced graphical output\n",
    "import random as rand# random number generation\n",
    "import sklearn.linear_model # to run different models\n",
    "import statsmodels.formula.api as smf # linear regression (statsmodels)\n",
    "from sklearn.model_selection import train_test_split  # train/test split\n",
    "from sklearn.neighbors import KNeighborsRegressor # KNN for Regression\n",
    "from sklearn.preprocessing import StandardScaler # standard scaler\n",
    "\n",
    "# pip install gender_guesser (remove # if you need to install it)\n",
    "import gender_guesser.detector as gender # guess gender based on (given) name\n",
    "\n",
    "# setting pandas print options (columns, rows, and display width)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "## 2. IMPORTING THE DATESET\n",
    "# Specifying the path and file name\n",
    "file = './data/Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "# Reading the file into Python\n",
    "ap_customers = pd.read_excel(io=file)\n",
    "\n",
    "## 3. CHANGING MISLABELD COLUMN NAME AND COLUMN PRESENTATION\n",
    "# Changing the name of largest_order_size to average_meals_ordered\n",
    "ap_customers.rename(columns={'LARGEST_ORDER_SIZE':'AVERAGE_MEALS_ORDERED'}, \n",
    "                    inplace=True)\n",
    "\n",
    "# Changing the capitalized columns to lowercase (personal preference)\n",
    "ap_customers.columns = map(str.lower, ap_customers.columns)\n",
    "\n",
    "## 4. SHOWING THE DATAFRAME\n",
    "# Checking if the data was imported and changed correctly \n",
    "ap_customers.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-driving",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## 2. Understanding the Data\n",
    "\n",
    "In the exploratory analysis, I made sure to get familiar with the data, checking the data types, null-values, definitions so that I can catogize them into continious, count/interval, and categorical variable types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blessed-zimbabwe",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Info & Descriptive Analysis \n",
    "\n",
    "## The number of non-null values / data type of each variable (remove # to run)\n",
    "# ap_customers.info()\n",
    "\n",
    "## The descriptive statistics of numeric variables (remove # to run)\n",
    "# ap_customers.describe(include = 'number').round(decimals=2)\n",
    "\n",
    "## The descriptive statistics of non-numeric variables (remove # to run)\n",
    "# ap_customers.describe(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "received-bermuda",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Checking the distribution of the response variable \"Revenue\" \n",
    "# developing a distribution of REVENUE\n",
    "sns.displot(data   = ap_customers,\n",
    "            x      = 'revenue',\n",
    "            height = 5,\n",
    "            aspect = 2)\n",
    "\n",
    "plt.title(label   = f\"\"\"Distribution of reponse variable \"Revenue\" \"\"\")\n",
    "plt.xlabel(xlabel = \"Revenue\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "# displaying the histogram\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-galaxy",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /> \n",
    "\n",
    "Due to the fact that Apprentice Chef want to know how much revenue they can expect from first-year customers, <b> the response variable will be revenue</b>. Based on the outputs above, I identified the data type of each original variable in the dataset: \n",
    "\n",
    "| Continuous                | Count/Interval              | Categorical  \n",
    "|:-------------------------:|:---------------------------:|:----------------------:|\n",
    "| revenue                   | avg_clicks_per_visit        | cross_sell_success     | \n",
    "| avg_time_per_site_visit   | unique_meals_purch          | name                   |\n",
    "| avg_prep_vid_time         | contacts_w_customer_service | email                  |\n",
    "|                           | product_categories_viewed   | first_name             |\n",
    "|                           | cancellations_before_noon   | family_name            |\n",
    "|                           | cancellations_after_noon    | mobile_number          |\n",
    "|                           | pc_logins\t                  | tastes_and_preferences |\n",
    "|                           | mobile_logins               | package_locker         |\n",
    "|                           | weekly_plan                 | refrigerated_locker    |\n",
    "|                           | early_deliveries            |                        |\n",
    "|                           | late_deliveries             |                        |\n",
    "|                           | master_classes_attended     |                        |\n",
    "|                           | average_meals_ordered       |                        |\n",
    "|                           | total_meals_ordered         |                        |\n",
    "|                           | total_photos_viewed         |                        |\n",
    "|                           | median_meals_rating.        |                        |\n",
    "|<img width=300/>|<img width=300/>|<img width=300/>|\n",
    "\n",
    "<h4> Other Insights </h4>\n",
    "\n",
    "* There are 47 people who did not have their family name registered in their profile.\n",
    "* The response variable is skewed towards the right and seems bi-modal. \n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /> \n",
    "\n",
    "## 3. Preperation Feature Engineering\n",
    "\n",
    "<b> Functions & Variables </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "literary-controversy",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Creating Specific placeholders for each of the variables \n",
    "\n",
    "# Creating an placeholder for delivery variables \n",
    "delivery_variables = ['early_deliveries', 'late_deliveries']\n",
    "\n",
    "# Creating an placeholder for cancellations variables \n",
    "cancellation_variables = ['cancellations_before_noon','cancellations_after_noon']\n",
    "\n",
    "# Creating an placeholder for behavior_variables\n",
    "behavior_variables = ['pc_logins', 'mobile_logins','avg_clicks_per_visit','product_categories_viewed', 'total_photos_viewed', 'median_meal_rating']\n",
    "\n",
    "# Creating an placeholder for service_variables\n",
    "purchase_variables = ['unique_meals_purch','average_meals_ordered','weekly_plan', \"total_meals_ordered\"]\n",
    "\n",
    "# Creating an placeholder for service_variables\n",
    "service_variables = ['contacts_w_customer_service','master_classes_attended']\n",
    "\n",
    "# Creating an placeholder for categorical_variables\n",
    "categorical_variables = ['name','email', 'first_name','family_name','mobile_number','cross_sell_success','tastes_and_preferences','package_locker', 'refrigerated_locker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "retired-barcelona",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Count the number of 0 values of each variables \n",
    "early_deliveries_no   = ap_customers['early_deliveries'].isin([0]).sum() \n",
    "late_deliveries_no = ap_customers['late_deliveries'].isin([0]).sum()\n",
    "cancellations_before_noon_no = ap_customers['cancellations_before_noon'].isin([0]).sum() \n",
    "cancellations_after_noon_no = ap_customers['cancellations_after_noon'].isin([0]).sum()\n",
    "total_photos_viewed_no = ap_customers['total_photos_viewed'].isin([0]).sum() \n",
    "product_categories_viewed_no = ap_customers['product_categories_viewed'].isin([0]).sum()\n",
    "pc_logins_no = ap_customers['pc_logins'].isin([0]).sum()\n",
    "mobile_logins_no = ap_customers['mobile_logins'].isin([0]).sum()\n",
    "avg_clicks_per_visit_no = ap_customers['avg_clicks_per_visit'].isin([0]).sum()\n",
    "total_meals_ordered_no = ap_customers['total_meals_ordered'].isin([0]).sum()\n",
    "average_meals_ordered_no = ap_customers['average_meals_ordered'].isin([0]).sum()\n",
    "weekly_plan_no = ap_customers['weekly_plan'].isin([0]).sum()\n",
    "unique_meals_purch_no = ap_customers['unique_meals_purch'].isin([0]).sum()\n",
    "master_classes_attended_no = ap_customers['master_classes_attended'].isin([0]).sum()\n",
    "contacts_w_customer_service_no = ap_customers['contacts_w_customer_service'].isin([0]).sum()\n",
    "median_meal_rating_no = ap_customers['median_meal_rating'].isin([0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "divine-instruction",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Copy the dataset to make changes with other variables \n",
    "\n",
    "# Make a copy\n",
    "ap_customer_2 = ap_customers.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-scheduling",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appreciated-nigeria",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGIGEERING: New variables \n",
    "##############################################################################\n",
    "#Variable: total cancellations\n",
    "ap_customer_2['total_cancellations'] = ap_customer_2['cancellations_before_noon'] + ap_customer_2['cancellations_after_noon']\n",
    "\n",
    "##############################################################################\n",
    "# Variable: Occasion \n",
    "# STEP 1: splitting personal emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in ap_customer_2.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = ap_customer_2.loc[index, 'email'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame to convert the email\n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# Creating a new list\n",
    "placeholder_lst2 = []\n",
    "\n",
    "#defining which emails belong to professional \n",
    "professional = ['mmm.com','amex.com','apple.com','boeing.com','caterpillar.com',\\\n",
    "                'chevron.com','cisco.com','cocacola.com','disney.com','dupont.com',\\\n",
    "                'exxon.com','ge.org','goldmansacs.com','homedepot.com','ibm.com',\\\n",
    "                'intel.com@jnj.com','jpmorgan.com','mcdonalds.com','merck.com',\\\n",
    "                'microsoft.com','nike.com','pfizer.com','pg.com','travelers.com',\\\n",
    "                'unitedtech.com','unitedhealth.com','verizon.com','visa.com',\\\n",
    "                'walmart.com']\n",
    "\n",
    "#defining which emails belong to personal\n",
    "personal = ['gmail.com','yahoo.com','protonmail.com']\n",
    "\n",
    "# loop over each variable to determine which category it is and put it in\n",
    "# a list\n",
    "for row in email_df[1]:\n",
    "    if row in professional: \n",
    "        placeholder_lst2.append('work')\n",
    "    elif row in personal:\n",
    "        placeholder_lst2.append('personal')\n",
    "    else: \n",
    "        placeholder_lst2.append('other')\n",
    "\n",
    "# Adding a new column to the dataframe \n",
    "ap_customer_2['occasion'] = placeholder_lst2  \n",
    "\n",
    "# Setting a placeholder\n",
    "occasion = ['occasion']\n",
    "\n",
    "# Getting the dummies for each of the occasions. \n",
    "occasion_dummies = pd.get_dummies(ap_customer_2['occasion'])\n",
    "\n",
    "# Dropping the original column\n",
    "ap_customer_2 = ap_customer_2.drop(columns= occasion)\n",
    "\n",
    "# Adding the dummies to the feature engieering dataset\n",
    "ap_customer_2 = ap_customer_2.join([occasion_dummies])\n",
    "\n",
    "##############################################################################\n",
    "# Creating a new variable: total order with a calculation of other variables\n",
    "ap_customer_2['total_orders'] = round(ap_customer_2['total_meals_ordered'] / ap_customer_2['average_meals_ordered'],2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "annual-afghanistan",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/estrellaspaans/opt/anaconda3/lib/python3.7/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING: Log variables \n",
    "# Creating a dataframe for all log values\n",
    "log_variables = ap_customer_2.copy()\n",
    "\n",
    "# Specifying which variables data types need to be changed to a float\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "# loop over datatypes to change the datatype\n",
    "for c in log_variables.columns: \n",
    "    if log_variables[c].dtype in numerics:\n",
    "        log_variables[c] = log_variables[c].astype(float)\n",
    "\n",
    "# Dropping all the variables that do not need changing\n",
    "log_variables = log_variables.drop(columns = categorical_variables) \n",
    "\n",
    "# Specifying whihch columns have 0 in the dataset.\n",
    "value_change_columns = [\"cancellations_before_noon\",\"cancellations_after_noon\",\"mobile_logins\",\"weekly_plan\",\"total_photos_viewed\", \"late_deliveries\", \"early_deliveries\", \"master_classes_attended\", \"total_cancellations\"]\n",
    "\n",
    "# Changing the 0 to 0.01 for a proper log transformation\n",
    "log_variables[value_change_columns] = log_variables[value_change_columns].replace({0.0:0.01})\n",
    "\n",
    "#loop over all values in columns to change it into log; \n",
    "for column in log_variables.columns:\n",
    "    try:\n",
    "        log_variables[column] = np.log10(log_variables[column])\n",
    "    except (ValueError, AttributeError):\n",
    "        pass\n",
    "\n",
    "# Adding log to each of the columsn to make it clear which are transformations\n",
    "log_variables.columns = [str(col) + '_log' for col in log_variables.columns]\n",
    "\n",
    "# Adding these columns to the feature engineering dataframe\n",
    "ap_customer_2 = pd.concat([ap_customer_2, log_variables],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tight-allergy",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: Continious variables \n",
    "\n",
    "# dummy variable for spending time on the website\n",
    "ap_customer_2['length_time_spent_website'] = 0\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in ap_customer_2.iterrows():\n",
    "    \n",
    "    # people that spend more than 60 minutes on the website\n",
    "    if ap_customer_2.loc[index, 'avg_time_per_site_visit'] > 60:\n",
    "        ap_customer_2.loc[index, 'length_time_spent_website'] = 1\n",
    "\n",
    "\n",
    "  # people that spend more less than 60 minutes on the website\n",
    "    if ap_customer_2.loc[index, 'avg_time_per_site_visit'] <=60:\n",
    "        ap_customer_2.loc[index, 'length_time_spent_website'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dietary-rings",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING: Count/Internal Variables \n",
    "\n",
    "#############################################################################\n",
    "#Delivery variables \n",
    "\n",
    "# dummy variable for having a basement.\n",
    "ap_customer_2['has_early_deliveries'] = 0\n",
    "ap_customer_2['has_late_deliveries'] = 0\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in ap_customer_2.iterrows():\n",
    "    \n",
    "    # has_early_deliveries \n",
    "    if ap_customer_2.loc[index, 'early_deliveries'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_early_deliveries'] = 1\n",
    "\n",
    "\n",
    "  # has_late_deliveries \n",
    "    if ap_customer_2.loc[index, 'late_deliveries'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_late_deliveries'] = 1\n",
    "\n",
    "#############################################################################\n",
    "#Cancellations variable\n",
    "\n",
    "#Creating a dummy variable\n",
    "ap_customer_2['has_cancellations']   = 0\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in ap_customer_2.iterrows():\n",
    "    \n",
    "    # has_cancellations_b_noon\n",
    "    if ap_customer_2.loc[index, 'total_cancellations'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_cancellations'] = 1\n",
    "        \n",
    "#############################################################################\n",
    "# Behavior Variables \n",
    "\n",
    "#Creating  dummy variables\n",
    "ap_customer_2['has_total_photos_viewed']   = 0\n",
    "ap_customer_2['has_mobile_logins']         = 0\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in ap_customer_2.iterrows():\n",
    "    \n",
    "    # has_early_deliveries \n",
    "    if ap_customer_2.loc[index, 'mobile_logins'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_mobile_logins'] = 1\n",
    "\n",
    "\n",
    "  # has_late_deliveries \n",
    "    if ap_customer_2.loc[index, 'total_photos_viewed'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_total_photos_viewed'] = 1\n",
    "\n",
    "#############################################################################\n",
    "# Purchase Variables \n",
    "\n",
    "#Creating a dummy variable\n",
    "ap_customer_2['has_weekly_plan']   = 0\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in ap_customer_2.iterrows():\n",
    "    \n",
    "    # has_early_deliveries \n",
    "    if ap_customer_2.loc[index, 'weekly_plan'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_weekly_plan'] = 1\n",
    "        \n",
    "\n",
    "#############################################################################\n",
    "# Service Variables \n",
    "\n",
    "#Creating a dummy variable\n",
    "ap_customer_2['has_master_classes_attended']   = 0\n",
    "\n",
    "# iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in ap_customer_2.iterrows():\n",
    "    \n",
    "    # has_early_deliveries \n",
    "    if ap_customer_2.loc[index, 'master_classes_attended'] > 0:\n",
    "        ap_customer_2.loc[index, 'has_master_classes_attended'] = 1\n",
    "        \n",
    "#############################################################################        \n",
    "#Splitting up the variables for ranking Because of high correlation\n",
    "\n",
    "# Using pd.get_dummies to get the different rankings\n",
    "ratings = pd.get_dummies(ap_customer_2['median_meal_rating'])\n",
    "\n",
    "#Giving the columns a name for each of the rankings \n",
    "ratings.columns = ['one_star_rank', 'two_star_rank', 'three_star_rank', 'four_star_rank','five_star_rank'] \n",
    "\n",
    "# Dropping the orihinal column\n",
    "ap_customer_2 = ap_customer_2.drop(columns=['median_meal_rating'])\n",
    "\n",
    "#Adding the new created columns to the feature engineering dataset\n",
    "ap_customer_2 = ap_customer_2.join([ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outer-legislation",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING Categorical Variables \n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "categorical_variables2 = ['name', 'first_name','email','family_name']\n",
    "\n",
    "# Cropping the columns that are not needed\n",
    "ap_customer_2 = ap_customer_2.drop(columns= categorical_variables2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "promotional-albany",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>cross_sell_success</th>\n",
       "      <th>total_meals_ordered</th>\n",
       "      <th>unique_meals_purch</th>\n",
       "      <th>contacts_w_customer_service</th>\n",
       "      <th>product_categories_viewed</th>\n",
       "      <th>avg_time_per_site_visit</th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>cancellations_before_noon</th>\n",
       "      <th>cancellations_after_noon</th>\n",
       "      <th>tastes_and_preferences</th>\n",
       "      <th>pc_logins</th>\n",
       "      <th>mobile_logins</th>\n",
       "      <th>weekly_plan</th>\n",
       "      <th>early_deliveries</th>\n",
       "      <th>late_deliveries</th>\n",
       "      <th>package_locker</th>\n",
       "      <th>refrigerated_locker</th>\n",
       "      <th>avg_prep_vid_time</th>\n",
       "      <th>average_meals_ordered</th>\n",
       "      <th>master_classes_attended</th>\n",
       "      <th>avg_clicks_per_visit</th>\n",
       "      <th>total_photos_viewed</th>\n",
       "      <th>total_cancellations</th>\n",
       "      <th>other</th>\n",
       "      <th>personal</th>\n",
       "      <th>work</th>\n",
       "      <th>total_orders</th>\n",
       "      <th>revenue_log</th>\n",
       "      <th>total_meals_ordered_log</th>\n",
       "      <th>unique_meals_purch_log</th>\n",
       "      <th>contacts_w_customer_service_log</th>\n",
       "      <th>product_categories_viewed_log</th>\n",
       "      <th>avg_time_per_site_visit_log</th>\n",
       "      <th>cancellations_before_noon_log</th>\n",
       "      <th>cancellations_after_noon_log</th>\n",
       "      <th>pc_logins_log</th>\n",
       "      <th>mobile_logins_log</th>\n",
       "      <th>weekly_plan_log</th>\n",
       "      <th>early_deliveries_log</th>\n",
       "      <th>late_deliveries_log</th>\n",
       "      <th>avg_prep_vid_time_log</th>\n",
       "      <th>average_meals_ordered_log</th>\n",
       "      <th>master_classes_attended_log</th>\n",
       "      <th>median_meal_rating_log</th>\n",
       "      <th>avg_clicks_per_visit_log</th>\n",
       "      <th>total_photos_viewed_log</th>\n",
       "      <th>total_cancellations_log</th>\n",
       "      <th>total_orders_log</th>\n",
       "      <th>length_time_spent_website</th>\n",
       "      <th>has_early_deliveries</th>\n",
       "      <th>has_late_deliveries</th>\n",
       "      <th>has_cancellations</th>\n",
       "      <th>has_total_photos_viewed</th>\n",
       "      <th>has_mobile_logins</th>\n",
       "      <th>has_weekly_plan</th>\n",
       "      <th>has_master_classes_attended</th>\n",
       "      <th>one_star_rank</th>\n",
       "      <th>two_star_rank</th>\n",
       "      <th>three_star_rank</th>\n",
       "      <th>four_star_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>48.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.594393</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.681241</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1.523746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.230449</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.602060</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1365.0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>40.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.135133</td>\n",
       "      <td>1.939519</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>0.90309</td>\n",
       "      <td>1.605844</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1.928396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>2.230449</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.939519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>19.77</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.903090</td>\n",
       "      <td>1.176091</td>\n",
       "      <td>0.845098</td>\n",
       "      <td>1.041393</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>1.296007</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.799341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1.204120</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>1.176091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.778151</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>1.041393</td>\n",
       "      <td>0.69897</td>\n",
       "      <td>1.954243</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>1.641474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1.146128</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>1.113943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>40.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.173186</td>\n",
       "      <td>1.672098</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.606166</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.903090</td>\n",
       "      <td>1.928396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477121</td>\n",
       "      <td>1.079181</td>\n",
       "      <td>2.311754</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.672098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   revenue  cross_sell_success  total_meals_ordered  unique_meals_purch  contacts_w_customer_service  product_categories_viewed  avg_time_per_site_visit  mobile_number  cancellations_before_noon  cancellations_after_noon  tastes_and_preferences  pc_logins  mobile_logins  weekly_plan  early_deliveries  late_deliveries  package_locker  refrigerated_locker  avg_prep_vid_time  average_meals_ordered  master_classes_attended  avg_clicks_per_visit  total_photos_viewed  total_cancellations  other  personal  work  total_orders  revenue_log  total_meals_ordered_log  unique_meals_purch_log  contacts_w_customer_service_log  product_categories_viewed_log  avg_time_per_site_visit_log  cancellations_before_noon_log  cancellations_after_noon_log  pc_logins_log  mobile_logins_log  weekly_plan_log  early_deliveries_log  late_deliveries_log  avg_prep_vid_time_log  average_meals_ordered_log  master_classes_attended_log  median_meal_rating_log  avg_clicks_per_visit_log  total_photos_viewed_log  \\\n",
       "0    393.0                   1                   14                   6                           12                         10                    48.00              1                          3                         1                       1          5              2            0                 0                2               0                    0               33.4                      1                        0                    17                    0                    4      0         0     1          14.0     2.594393                 1.146128                0.778151                         1.079181                        1.00000                     1.681241                       0.477121                           0.0       0.698970            0.30103        -2.000000                  -2.0             0.301030               1.523746                        0.0                         -2.0                0.000000                  1.230449                -2.000000   \n",
       "1   1365.0                   1                   87                   3                            8                          8                    40.35              1                          0                         0                       1          5              1           12                 0                2               0                    0               84.8                      1                        0                    13                  170                    0      0         0     1          87.0     3.135133                 1.939519                0.477121                         0.903090                        0.90309                     1.605844                      -2.000000                          -2.0       0.698970            0.00000         1.079181                  -2.0             0.301030               1.928396                        0.0                         -2.0                0.477121                  1.113943                 2.230449   \n",
       "2    800.0                   1                   15                   7                           11                          5                    19.77              1                          3                         0                       1          6              1            1                 0                1               0                    0               63.0                      1                        0                    16                    0                    3      1         0     0          15.0     2.903090                 1.176091                0.845098                         1.041393                        0.69897                     1.296007                       0.477121                          -2.0       0.778151            0.00000         0.000000                  -2.0             0.000000               1.799341                        0.0                         -2.0                0.301030                  1.204120                -2.000000   \n",
       "3    600.0                   1                   13                   6                           11                          5                    90.00              1                          2                         0                       1          6              1           14                 0                3               0                    0               43.8                      1                        0                    14                    0                    2      0         0     1          13.0     2.778151                 1.113943                0.778151                         1.041393                        0.69897                     1.954243                       0.301030                          -2.0       0.778151            0.00000         1.146128                  -2.0             0.477121               1.641474                        0.0                         -2.0                0.301030                  1.146128                -2.000000   \n",
       "4   1490.0                   1                   47                   8                            6                         10                    40.38              1                          0                         0                       0          5              1            5                 0                8               0                    0               84.8                      1                        1                    12                  205                    0      1         0     0          47.0     3.173186                 1.672098                0.903090                         0.778151                        1.00000                     1.606166                      -2.000000                          -2.0       0.698970            0.00000         0.698970                  -2.0             0.903090               1.928396                        0.0                          0.0                0.477121                  1.079181                 2.311754   \n",
       "\n",
       "   total_cancellations_log  total_orders_log  length_time_spent_website  has_early_deliveries  has_late_deliveries  has_cancellations  has_total_photos_viewed  has_mobile_logins  has_weekly_plan  has_master_classes_attended  one_star_rank  two_star_rank  three_star_rank  four_star_rank  \n",
       "0                 0.602060          1.146128                          0                     0                    1                  1                        0                  1                0                            0              1              0                0               0  \n",
       "1                -2.000000          1.939519                          0                     0                    1                  0                        1                  1                1                            0              0              0                1               0  \n",
       "2                 0.477121          1.176091                          0                     0                    1                  1                        0                  1                1                            0              0              1                0               0  \n",
       "3                 0.301030          1.113943                          1                     0                    1                  1                        0                  1                1                            0              0              1                0               0  \n",
       "4                -2.000000          1.672098                          0                     0                    1                  0                        1                  1                1                            1              0              0                1               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking_Final Dataset \n",
    "\n",
    "# Creating a variables that shows all the columns that need to be dropped\n",
    "drop_final = ['other_log','personal_log','work_log','five_star_rank']\n",
    "# Dropping the final variables that are not supposed to be created\n",
    "ap_customer_2=ap_customer_2.drop(columns=drop_final)\n",
    "\n",
    "#Showing the final dataset with feature engineering variables. \n",
    "ap_customer_2.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-single",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /> \n",
    "\n",
    "## 5. Model Development\n",
    "\n",
    "### Distribution of Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "documentary-profile",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot distribution of revenue and log_revenue \n",
    "## CHANGE plt.close() to plt.show() TO DISPLAY THE GRAPHS\n",
    "\n",
    "# Setting size of the plots and how many plots are shown next to each other:\n",
    "fig, ax = plt.subplots(figsize=(20, 6), ncols=2)\n",
    "\n",
    "#Developing a plot for the distribution of log_revenue \n",
    "sns.histplot(data   = ap_customer_2,\n",
    "             x      = 'revenue_log', \n",
    "             ax     = ax[0]) #showing the location (first plot)\n",
    "\n",
    "#Developing a plot for the distribution of log_revenue \n",
    "sns.histplot(data   = ap_customer_2,\n",
    "             x      = 'revenue', \n",
    "             color = \"skyblue\",\n",
    "             ax     = ax[1]) #showing the location (second plot)\n",
    "\n",
    "# Setting the titles for each plot\n",
    "ax[0].set_title('Distribution of Log Revenue') \n",
    "ax[1].set_title('Distribution of Original Revenue')\n",
    "\n",
    "# displaying the histogram\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-spouse",
   "metadata": {},
   "source": [
    "When performing regressions, it is important that the response variable is normally distrubited and does not show any kurtosis or skewness. In this case, \"revenue\" has some skewness to the right. Therefore, I applied a log transformation to the variable to see whether this would make a difference. The bi-modelness of the variable will be ignored for now and changed, if needed, after creating the first regression models.\n",
    "\n",
    "\n",
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sorted-bikini",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_clicks_per_visit_log</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_clicks_per_visit</th>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_star_rank</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_star_rank</th>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_meals_purch_log</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_meals_purch</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellations_after_noon_log</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellations_after_noon</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_weekly_plan</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_plan_log</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_late_deliveries</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_logins</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length_time_spent_website</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late_deliveries_log</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_logins_log</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late_deliveries</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package_locker</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three_star_rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_cancellations</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_sell_success</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refrigerated_locker</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_deliveries</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellations_before_noon</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_mobile_logins</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>early_deliveries_log</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc_logins_log</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tastes_and_preferences</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_cancellations_log</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_categories_viewed_log</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_plan</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_early_deliveries</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_cancellations</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellations_before_noon_log</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc_logins</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile_number</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_categories_viewed</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contacts_w_customer_service</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time_per_site_visit</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time_per_site_visit_log</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contacts_w_customer_service_log</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_orders</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_total_photos_viewed</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_photos_viewed_log</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_meals_ordered_log</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_orders_log</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_meals_ordered</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_classes_attended</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_master_classes_attended</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>master_classes_attended_log</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_photos_viewed</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_meal_rating_log</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_star_rank</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_meals_ordered</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_meals_ordered_log</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_prep_vid_time_log</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_prep_vid_time</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 revenue  revenue_log\n",
       "avg_clicks_per_visit_log           -0.56        -0.58\n",
       "avg_clicks_per_visit               -0.55        -0.58\n",
       "two_star_rank                      -0.37        -0.42\n",
       "one_star_rank                      -0.20        -0.28\n",
       "unique_meals_purch_log             -0.12        -0.13\n",
       "unique_meals_purch                 -0.06        -0.08\n",
       "cancellations_after_noon_log       -0.04        -0.04\n",
       "cancellations_after_noon           -0.04        -0.04\n",
       "has_weekly_plan                    -0.03        -0.03\n",
       "weekly_plan_log                    -0.02        -0.02\n",
       "has_late_deliveries                -0.02        -0.02\n",
       "mobile_logins                      -0.02        -0.01\n",
       "length_time_spent_website          -0.02        -0.00\n",
       "late_deliveries_log                -0.01        -0.02\n",
       "mobile_logins_log                  -0.01        -0.01\n",
       "other                              -0.01        -0.01\n",
       "late_deliveries                    -0.01        -0.02\n",
       "package_locker                     -0.01        -0.02\n",
       "three_star_rank                     0.00         0.12\n",
       "total_cancellations                 0.00        -0.00\n",
       "work                               -0.00        -0.01\n",
       "cross_sell_success                  0.00         0.01\n",
       "refrigerated_locker                -0.00        -0.01\n",
       "early_deliveries                   -0.00        -0.01\n",
       "cancellations_before_noon           0.01         0.01\n",
       "has_mobile_logins                   0.01        -0.00\n",
       "early_deliveries_log                0.01        -0.00\n",
       "pc_logins_log                       0.01         0.01\n",
       "tastes_and_preferences              0.01         0.01\n",
       "total_cancellations_log             0.01         0.01\n",
       "product_categories_viewed_log       0.01         0.01\n",
       "weekly_plan                         0.01         0.01\n",
       "has_early_deliveries                0.01         0.00\n",
       "has_cancellations                   0.01         0.01\n",
       "personal                            0.01         0.01\n",
       "cancellations_before_noon_log       0.02         0.01\n",
       "pc_logins                           0.02         0.01\n",
       "mobile_number                       0.03         0.04\n",
       "product_categories_viewed           0.03         0.04\n",
       "contacts_w_customer_service         0.10        -0.04\n",
       "avg_time_per_site_visit             0.14         0.14\n",
       "avg_time_per_site_visit_log         0.15         0.15\n",
       "contacts_w_customer_service_log     0.17         0.05\n",
       "total_orders                        0.36         0.40\n",
       "has_total_photos_viewed             0.37         0.39\n",
       "total_photos_viewed_log             0.40         0.41\n",
       "average_meals_ordered_log           0.42         0.45\n",
       "total_orders_log                    0.43         0.50\n",
       "average_meals_ordered               0.44         0.45\n",
       "master_classes_attended             0.45         0.47\n",
       "has_master_classes_attended         0.45         0.48\n",
       "master_classes_attended_log         0.46         0.49\n",
       "total_photos_viewed                 0.47         0.43\n",
       "median_meal_rating_log              0.55         0.61\n",
       "four_star_rank                      0.59         0.53\n",
       "total_meals_ordered                 0.60         0.61\n",
       "total_meals_ordered_log             0.61         0.69\n",
       "avg_prep_vid_time_log               0.63         0.67\n",
       "avg_prep_vid_time                   0.64         0.65"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CORRELATIONS \n",
    "# Creating correlation matrix, round them, and sort them\n",
    "df_corr = ap_customer_2.corr().round(2).sort_values('revenue')\n",
    "\n",
    "# Create overview that shows the correlation with log revenue and revenue\n",
    "df_corr.loc[:'avg_prep_vid_time',['revenue','revenue_log']   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "breeding-stress",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            revenue_log   R-squared:                       0.715\n",
      "Model:                            OLS   Adj. R-squared:                  0.713\n",
      "Method:                 Least Squares   F-statistic:                     330.3\n",
      "Date:                Tue, 09 Feb 2021   Prob (F-statistic):               0.00\n",
      "Time:                        23:52:21   Log-Likelihood:                 1127.8\n",
      "No. Observations:                1459   AIC:                            -2232.\n",
      "Df Residuals:                    1447   BIC:                            -2168.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                       2.4739      0.051     48.660      0.000       2.374       2.574\n",
      "total_orders                   -0.0041      0.000     -9.788      0.000      -0.005      -0.003\n",
      "total_meals_ordered_log         0.4659      0.020     23.439      0.000       0.427       0.505\n",
      "unique_meals_purch_log         -0.1345      0.012    -11.181      0.000      -0.158      -0.111\n",
      "contacts_w_customer_service     0.0099      0.002      6.496      0.000       0.007       0.013\n",
      "avg_time_per_site_visit_log     0.0872      0.022      3.975      0.000       0.044       0.130\n",
      "master_classes_attended_log     0.0283      0.003      8.576      0.000       0.022       0.035\n",
      "total_photos_viewed_log         0.0063      0.002      4.038      0.000       0.003       0.009\n",
      "length_time_spent_website      -0.1005      0.013     -8.039      0.000      -0.125      -0.076\n",
      "one_star_rank                  -0.1036      0.015     -6.730      0.000      -0.134      -0.073\n",
      "two_star_rank                  -0.0647      0.008     -8.328      0.000      -0.080      -0.049\n",
      "four_star_rank                  0.1336      0.010     13.087      0.000       0.114       0.154\n",
      "==============================================================================\n",
      "Omnibus:                      131.651   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              510.440\n",
      "Skew:                          -0.364   Prob(JB):                    1.44e-111\n",
      "Kurtosis:                       5.805   Cond. No.                         408.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# BEST OLS Model According to StatsModels \n",
    "# Creating a new dataset to make sure everything works fine. \n",
    "model_test = ap_customer_2.copy()\n",
    "\n",
    "#Dropping the reponse variables from the dataset \n",
    "model_data = ap_customer_2.drop(columns=['revenue', 'revenue_log'])\n",
    "\n",
    "#Setting the target response (either revenue or log revenue)\n",
    "target_t1 = model_test.loc[ : ,'revenue']\n",
    "target_t2 = model_test.loc[ : , 'revenue_log'] # ready for use later\n",
    "\n",
    "# Splitting up the data for training and testing focus: log_revenue\n",
    "x_train_test, x_test_test, y_train_test, y_test_test = train_test_split(\n",
    "            model_data,\n",
    "            target_t2,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "# Merging training data together for Linear Regression from Statsmodel to work\n",
    "test_train = pd.concat([x_train_test, y_train_test], axis = 1)\n",
    "\n",
    "\n",
    "# Step 1: build a model in StatsModels \n",
    "lm_best = smf.ols(formula =  \"\"\"revenue_log ~ \n",
    "                            total_orders +\n",
    "                            total_meals_ordered_log +\n",
    "                            unique_meals_purch_log +\n",
    "                            contacts_w_customer_service +\n",
    "                            avg_time_per_site_visit_log +\n",
    "                            master_classes_attended_log +\n",
    "                            total_photos_viewed_log+\n",
    "                            length_time_spent_website +\n",
    "                            one_star_rank +\n",
    "                            two_star_rank +\n",
    "                            four_star_rank\"\"\",data = test_train)\n",
    "\n",
    "# Step 2: fit the model based on the data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "# Step 3: analyze the summary output\n",
    "print(results.summary())\n",
    "\n",
    "# Creating a list with all the variables used: x_variables\n",
    "x_variables = ['avg_prep_vid_time','average_meals_ordered', 'total_orders', 'total_meals_ordered_log','unique_meals_purch_log', 'contacts_w_customer_service','avg_time_per_site_visit_log', 'master_classes_attended_log','total_photos_viewed_log','length_time_spent_website','one_star_rank', 'two_star_rank', 'four_star_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-gallery",
   "metadata": {},
   "source": [
    "### Model 1: OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "following-doctor",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Training Score : 0.7459\n",
      "OLS Testing Score  : 0.7569\n",
      "OLS Train-Test Gap : 0.011\n",
      "('intercept', 2.5528)\n",
      "('avg_prep_vid_time', 0.0014)\n",
      "('average_meals_ordered', -0.0256)\n",
      "('total_orders', -0.0036)\n",
      "('total_meals_ordered_log', 0.3998)\n",
      "('unique_meals_purch_log', -0.1363)\n",
      "('contacts_w_customer_service', 0.0059)\n",
      "('avg_time_per_site_visit_log', 0.0503)\n",
      "('master_classes_attended_log', 0.0183)\n",
      "('total_photos_viewed_log', 0.0059)\n",
      "('length_time_spent_website', -0.0815)\n",
      "('one_star_rank', -0.0884)\n",
      "('two_star_rank', -0.0518)\n",
      "('four_star_rank', 0.1261)\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1 - OLS Rsponse: revenue_log \n",
    "#############################################################################\n",
    "model_1 = ap_customer_2.copy()\n",
    "\n",
    "model_1_data = model_1[['avg_prep_vid_time','average_meals_ordered', 'total_orders', 'total_meals_ordered_log','unique_meals_purch_log', 'contacts_w_customer_service','avg_time_per_site_visit_log', 'master_classes_attended_log','total_photos_viewed_log','length_time_spent_website','one_star_rank', 'two_star_rank', 'four_star_rank']]\n",
    "                                        \n",
    "target_1 = model_1.loc[ : ,'revenue']\n",
    "target_2 = model_1.loc[ : , 'revenue_log'] # ready for use later\n",
    "\n",
    "x_train_model_1, x_test_model_1, y_train_model_1, y_test_model_1 = train_test_split(\n",
    "    model_1_data,\n",
    "    target_2,\n",
    "    test_size = 0.25,\n",
    "    random_state = 219)\n",
    "\n",
    "#############################################################################\n",
    "lr1 = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr1_fit = lr1.fit(x_train_model_1, y_train_model_1)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr1_pred = lr1_fit.predict(x_test_model_1)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr1.score(x_train_model_1, y_train_model_1).round(4))  # using R-square\n",
    "print('OLS Testing Score  :', lr1.score(x_test_model_1, y_test_model_1).round(4)) # using R-square\n",
    "\n",
    "lr1_train_score = lr1.score(x_train_model_1, y_train_model_1).round(4)\n",
    "lr1_test_score  = lr1.score(x_test_model_1, y_test_model_1).round(4)\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr1_train_score - lr1_test_score).round(4))\n",
    "lr1_test_gap = abs(lr1_train_score - lr1_test_score).round(4)\n",
    "\n",
    "# zipping each feature name to its coefficient\n",
    "lr1_model_values = zip(model_1_data[x_variables].columns,\n",
    "                      lr1_fit.coef_.round(decimals = 4))\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr1_model_lst = [('intercept', lr1_fit.intercept_.round(decimals = 4))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr1_model_values:\n",
    "    lr1_model_lst.append(val)\n",
    "    \n",
    "# checking the results\n",
    "for pair in lr1_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-donna",
   "metadata": {},
   "source": [
    "### Model 2: Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ideal-peeing",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Training Score : 0.6996\n",
      "Lasso Testing Score  : 0.7398\n",
      "Lasso Train-Test Gap : 0.0402\n",
      "('intercept', -1454.1014)\n",
      "('avg_prep_vid_time', 8.8439)\n",
      "('average_meals_ordered', -122.5332)\n",
      "('total_orders', -9.5141)\n",
      "('total_meals_ordered_log', 1576.6577)\n",
      "('unique_meals_purch_log', -694.8131)\n",
      "('contacts_w_customer_service', 66.1907)\n",
      "('avg_time_per_site_visit_log', 250.2256)\n",
      "('master_classes_attended_log', 87.0299)\n",
      "('total_photos_viewed_log', 25.9429)\n",
      "('length_time_spent_website', -458.1933)\n",
      "('one_star_rank', -159.7424)\n",
      "('two_star_rank', -131.0571)\n",
      "('four_star_rank', 912.339)\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2 - Lasso Response: Revenue \n",
    "\n",
    "# Creating a new dataset to make sure everything works fine. \n",
    "model_2 = ap_customer_2.copy()\n",
    "\n",
    "# Subsetting the data in order to have the right variables \n",
    "model_2_data = model_2[['avg_prep_vid_time','average_meals_ordered', 'total_orders', 'total_meals_ordered_log','unique_meals_purch_log', 'contacts_w_customer_service','avg_time_per_site_visit_log', 'master_classes_attended_log','total_photos_viewed_log','length_time_spent_website','one_star_rank', 'two_star_rank', 'four_star_rank']]\n",
    "\n",
    "# Creating target variables \n",
    "target_1 = model_2.loc[ : ,'revenue']\n",
    "target_2 = model_2.loc[ : , 'revenue_log'] # ready for use later\n",
    "\n",
    "# Splitting up the data for training and testing focus: log_revenue\n",
    "x_train_model_2, x_test_model_2, y_train_model_2, y_test_model_2 = train_test_split(\n",
    "            model_2_data,\n",
    "            target_1,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "# CINSTANTIATING a lasso model\n",
    "lasso_model = sklearn.linear_model.Lasso()\n",
    "\n",
    "# FITTING to the training data\n",
    "lasso_fit = lasso_model.fit(x_train_model_2, y_train_model_2)\n",
    "\n",
    "# PREDICTING on new data\n",
    "lasso_pred = lasso_fit.predict(x_test_model_2)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_model_2, y_train_model_2).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_model_2, y_test_model_2).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_model_2, y_train_model_2).round(4) # using R-square\n",
    "lasso_test_score  = lasso_model.score(x_test_model_2, y_test_model_2).round(4)   # using R-square\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)\n",
    "\n",
    "\n",
    "# zipping each feature name to its coefficient\n",
    "lasso_model_values = zip(model_2_data[x_variables].columns,\n",
    "                      lasso_fit.coef_.round(decimals = 4))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 4))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adopted-pencil",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train Score        Test Score\n",
      "-----                  -----------        ----------\n",
      "OLS (revenue_log)      0.7459             0.7569\n",
      "Lasso (revenue)        0.6996             0.7398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing OLS & LASSO results \n",
    "\n",
    "# Printing the results\n",
    "print(f\"\"\"\n",
    "Model                  Train Score        Test Score\n",
    "-----                  -----------        ----------\n",
    "OLS (revenue_log)      {lr1_train_score}             {lr1_test_score}\n",
    "Lasso (revenue)        {lasso_train_score}             {lasso_test_score}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "performance = {\n",
    "    \n",
    "    'Model Type'    : ['OLS', 'Lasso'],\n",
    "           \n",
    "    'Training' : [lr1_train_score, lasso_train_score],\n",
    "           \n",
    "    'Testing'  : [lr1_test_score, lasso_test_score],\n",
    "                    \n",
    "    'Train-Test Gap' : [lr1_test_gap, lasso_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lr1_model_lst), len(lasso_model_lst)],\n",
    "                    \n",
    "    'Model' : [lr1_model_lst, lasso_model_lst]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "performance = pd.DataFrame(performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "performance.to_excel('./performance_model.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-present",
   "metadata": {},
   "source": [
    "### Model 3: KNN Non-Standardized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "utility-preview",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Score: 0.7019\n",
      "KNN Testing Score : 0.6645\n",
      "KNN Train-Test Gap: 0.0374\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3 - KNN Non-Standardized Data Response: revenue_log \n",
    "model_3 = ap_customer_2.copy()\n",
    "\n",
    "model_3_data = model_3[['avg_prep_vid_time','average_meals_ordered', 'total_orders', 'total_meals_ordered_log','unique_meals_purch_log', 'contacts_w_customer_service','avg_time_per_site_visit_log', 'master_classes_attended_log','total_photos_viewed_log','length_time_spent_website','one_star_rank', 'two_star_rank', 'four_star_rank']]\n",
    "                                        \n",
    "target_1 = model_3.loc[ : ,'revenue']\n",
    "target_2 = model_3.loc[ : , 'revenue_log'] # ready for use later\n",
    "\n",
    "x_train_model_3, x_test_model_3, y_train_model_3, y_test_model_3 = train_test_split(\n",
    "    model_3_data,\n",
    "    target_2,\n",
    "    test_size = 0.25,\n",
    "    random_state = 219)\n",
    "\n",
    "knn_reg = KNeighborsRegressor(algorithm = 'auto',\n",
    "                              n_neighbors = 10)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# FITTING the model based on the training data\n",
    "knn_reg_fit = knn_reg.fit(x_train_model_3, y_train_model_3)\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_reg_pred = knn_reg_fit.predict(x_test_model_3)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('KNN Training Score:', knn_reg.score(x_train_model_3, y_train_model_3).round(4))\n",
    "print('KNN Testing Score :',  knn_reg.score(x_test_model_3, y_test_model_3).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_reg_score_train = knn_reg.score(x_train_model_3, y_train_model_3).round(4)\n",
    "knn_reg_score_test  = knn_reg.score(x_test_model_3, y_test_model_3).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_reg_score_train - knn_reg_score_test).round(4))\n",
    "knn_reg_test_gap = abs(knn_reg_score_train - knn_reg_score_test).round(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-current",
   "metadata": {},
   "source": [
    "### Model 4: KNN Standardized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tested-crash",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training Score: 0.7864\n",
      "KNN Testing Score : 0.7849\n",
      "KNN Train-Test Gap: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4 - KNN Standardized Data Response: revenue_log \n",
    "\n",
    "#SUBSETTING original dataset\n",
    "model_4_data = ap_customer_2[['avg_prep_vid_time','average_meals_ordered', 'total_orders', 'total_meals_ordered_log','unique_meals_purch_log', 'contacts_w_customer_service','avg_time_per_site_visit_log', 'master_classes_attended_log','total_photos_viewed_log','length_time_spent_website','one_star_rank', 'two_star_rank', 'four_star_rank']]\n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FITTING the scaler with housing_data\n",
    "scaler.fit(model_4_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(model_4_data)\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled)\n",
    "\n",
    "#New training data\n",
    "X_train_STAND, X_test_STAND, y_train_STAND, y_test_STAND = train_test_split(\n",
    "            X_scaled_df,\n",
    "            target_2,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "# INSTANTIATING a model with the optimal number of neighbors\n",
    "knn_stand = KNeighborsRegressor(algorithm = 'auto',\n",
    "                   n_neighbors = 23)\n",
    "\n",
    "\n",
    "# FITTING the model based on the training data\n",
    "knn_stand_fit = knn_stand.fit(X_train_STAND, y_train_STAND)\n",
    "\n",
    "\n",
    "# PREDITCING on new data\n",
    "knn_stand_pred = knn_stand_fit.predict(X_test_STAND)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('KNN Training Score:', knn_stand.score(X_train_STAND,y_train_STAND).round(4))\n",
    "print('KNN Testing Score :', knn_stand.score(X_test_STAND, y_test_STAND).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_stand_score_train = knn_stand.score(X_train_STAND,y_train_STAND).round(4)\n",
    "knn_stand_score_test  = knn_stand.score(X_test_STAND, y_test_STAND).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_stand_score_train - knn_stand_score_test).round(4))\n",
    "knn_stand_test_gap = abs(knn_stand_score_train - knn_stand_score_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "secure-brunswick",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Model             Neighbors     Train Score      Test Score\n",
      "----------------      ---------     ----------       ----------\n",
      "Non-Standardized      10             0.7019            0.6645\n",
      "Standardized          23             0.7864           0.7849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing KNN results \n",
    "\n",
    "print(f\"\"\"\n",
    "KNN Model             Neighbors     Train Score      Test Score\n",
    "----------------      ---------     ----------       ----------\n",
    "Non-Standardized      10             {knn_reg_score_train}            {knn_reg_score_test}\n",
    "Standardized          23             {knn_stand_score_train}           {knn_stand_score_test}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['KNN_Not_Standardized', 'KNN_Standardized_Opt FINAL MODEL'],\n",
    "           \n",
    "    \n",
    "    'Training' : [knn_reg_score_train,\n",
    "                  knn_stand_score_train],\n",
    "           \n",
    "    \n",
    "    'Testing'  : [knn_reg_score_test,\n",
    "                  knn_stand_score_test],\n",
    "                    \n",
    "    \n",
    "    'Train-Test Gap' : [knn_reg_test_gap,\n",
    "                        knn_stand_test_gap],\n",
    "                   \n",
    "    \n",
    "    'Model Size' : [\"NA\", \" NA\"],\n",
    "                    \n",
    "    'Model'      : [\"NA\", \"NA\"] }\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "prompt-significance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Type</th>\n",
       "      <th>Training</th>\n",
       "      <th>Testing</th>\n",
       "      <th>Train-Test Gap</th>\n",
       "      <th>Model Size</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>14</td>\n",
       "      <td>[(intercept, 2.5528), (avg_prep_vid_time, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.7398</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>14</td>\n",
       "      <td>[(intercept, -1454.1014), (avg_prep_vid_time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN_Not_Standardized</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN_Standardized_Opt FINAL MODEL</td>\n",
       "      <td>0.7864</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Type  Training  Testing  Train-Test Gap Model Size                                              Model\n",
       "0                               OLS    0.7459   0.7569          0.0110         14  [(intercept, 2.5528), (avg_prep_vid_time, 0.00...\n",
       "1                             Lasso    0.6996   0.7398          0.0402         14  [(intercept, -1454.1014), (avg_prep_vid_time, ...\n",
       "0              KNN_Not_Standardized    0.7019   0.6645          0.0374         NA                                                 NA\n",
       "1  KNN_Standardized_Opt FINAL MODEL    0.7864   0.7849          0.0015         NA                                                 NA"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# concatenating with former performance DataFrame\n",
    "total_performance = pd.concat([performance, model_performance],\n",
    "                              axis = 0)\n",
    "\n",
    "\n",
    "total_performance.sort_values(by = 'Testing',\n",
    "                              ascending = False)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "total_performance.to_excel('./performance.xlsx',\n",
    "                           index = False)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "total_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-processing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
